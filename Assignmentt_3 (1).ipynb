{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " ---\n",
        " ---\n",
        "   **Problem Formulation** \n",
        "\n",
        " ---\n",
        " ---\n",
        "\n",
        "*  **The input:** \n",
        " *  Training dat (data) : it containd the features and the label data.\n",
        " *  Testing data (test) : it contains the features.\n",
        "\n",
        "* **the output**\n",
        " * it will be the label data (the raiting column) \n",
        "\n",
        "*  **Function used**  \n",
        " *   classification\n",
        "\n",
        " *   predection\n",
        "\n",
        "*   **Challenges**\n",
        "\n",
        " *   The dataset is not clean, and we need some preprocessing depending on the models we choice,\n",
        " \n",
        " - changing the multipul  hyperparameter to give a good accuracy/f1 score\n",
        "\n",
        "*    **the imapct** \n",
        " *   the impact that the model will fits will on the training data and predect well on the test data or any data that we enter, And that will have a huge impact in real life if that uesd we will be able to predect right and proratize what is important.\n",
        " \n",
        " - we are going to be able to evaluate our mdels correctly and we can help the customer to find what they really want. \n",
        "\n",
        "*    **ideal solution**\n",
        " *   the ideal solutition happens when our model is able to classify and predict very well on any data the model gets , And also that happens when our data is cleaned perfectly  and \n",
        "\n",
        " - it happens when choose the perfecrt model who can deals with type of dat and not to forget the gyperparameter tuning .\n",
        "\n",
        "----\n",
        "\n",
        "**the experimental protocol used is 'Hold out method'**\n",
        "\n",
        "The following is the process of using the hold-out method for model evaluation:\n",
        "\n",
        "- Split the dataset into two parts \n",
        "\n",
        "- Train the model on the training dataset; While training the model, some fixed set of hyper parameters is selected.\n",
        "\n",
        "- Test or evaluate the model on the held-out test dataset\n",
        "Train the final model on the entire dataset to get a model which can generalize better on the unseen or future dataset. \n",
        "---\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "imtyOn1BIbKw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNrP6A-6heqF"
      },
      "source": [
        "##**Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEHTD107T-6O",
        "outputId": "a50c081c-9b88-4f09-8acd-5aa93cd6dc9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pbz6_xzwg8UE"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import holoviews as hv\n",
        "import nltk \n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aw_UMi6hhO0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV \n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import PredefinedSplit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTLYgJcBhl0s"
      },
      "source": [
        "##Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8wziNAXhhRk"
      },
      "outputs": [],
      "source": [
        "# Read the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/DM_assignment_3/xy_train.csv', sep=\",\", na_values=[\"\"])\n",
        "test = pd.read_csv('/content/drive/MyDrive/DM_assignment_3/x_test.csv', sep=\",\", na_values=[\"\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kswnAB03hv7l"
      },
      "source": [
        "##**Over view of the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyLBgjCVfzA9"
      },
      "source": [
        "---\n",
        "**the over view always help us take a better look over tge data and help us realize anything needed to be fixed sometimes**.\n",
        "**As we can see that there were the id column and we needed to drop it from the training and test data**. \n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KSnv_J3AiEHl",
        "outputId": "b7f7c0d3-073b-4c11-d517-8c379555fa8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                               text  label\n",
              "0      265723  A group of friends began to volunteer at a hom...      0\n",
              "1      284269  British Prime Minister @Theresa_May on Nerve A...      0\n",
              "2      207715  In 1961, Goodyear released a kit that allows P...      0\n",
              "3      551106  Happy Birthday, Bob Barker! The Price Is Right...      0\n",
              "4        8584  Obama to Nation: 聙\"Innocent Cops and Unarmed Y...      0\n",
              "...       ...                                                ...    ...\n",
              "59995   70046  Finish Sniper Simo H盲yh盲 during the invasion o...      0\n",
              "59996  189377  Nigerian Prince Scam took $110K from Kansas ma...      1\n",
              "59997   93486  Is It Safe To Smoke Marijuana During Pregnancy...      0\n",
              "59998  140950  Julius Caesar upon realizing that everyone in ...      0\n",
              "59999   34509  Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...      1\n",
              "\n",
              "[60000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96af3492-2e17-470c-ac75-d271e6f3d1d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a hom...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows P...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>70046</td>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>189377</td>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>93486</td>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>140950</td>\n",
              "      <td>Julius Caesar upon realizing that everyone in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>34509</td>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96af3492-2e17-470c-ac75-d271e6f3d1d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96af3492-2e17-470c-ac75-d271e6f3d1d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96af3492-2e17-470c-ac75-d271e6f3d1d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CrwSBSgilIr8",
        "outputId": "250b652f-3482-4be2-c3d2-214fca37ea28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id                                               text\n",
              "0          0                                         stargazer \n",
              "1          1                                               yeah\n",
              "2          2  PD: Phoenix car thief gets instructions from Y...\n",
              "3          3  As Trump Accuses Iran, He Has One Problem: His...\n",
              "4          4                       \"Believers\" - Hezbollah 2011\n",
              "...      ...                                                ...\n",
              "59146  59146                  Bicycle taxi drivers of New Delhi\n",
              "59147  59147  Trump blows up GOP's formula for winning House...\n",
              "59148  59148  Napoleon returns from his exile on the island ...\n",
              "59149  59149   Deep down he always wanted to be a ballet dancer\n",
              "59150  59150  Toddler miraculously survives 6-story fall lan...\n",
              "\n",
              "[59151 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af5da49d-530d-4842-8b1d-63f7fecb8b6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PD: Phoenix car thief gets instructions from Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>59146</td>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>59147</td>\n",
              "      <td>Trump blows up GOP's formula for winning House...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>59148</td>\n",
              "      <td>Napoleon returns from his exile on the island ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>59149</td>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>59150</td>\n",
              "      <td>Toddler miraculously survives 6-story fall lan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af5da49d-530d-4842-8b1d-63f7fecb8b6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af5da49d-530d-4842-8b1d-63f7fecb8b6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af5da49d-530d-4842-8b1d-63f7fecb8b6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b5r6UVKi3Tr"
      },
      "outputs": [],
      "source": [
        "# save tge id for later use we we writting the output in the file\n",
        "id_ = data['id']\n",
        "id_test = test['id']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7uHlS8QiShM"
      },
      "source": [
        "##Dropping the id"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "`if we didn't drop the id it will cause a miss leading in the classification.`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "bqA-v_NeJWDW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzKGPPjnhhTz"
      },
      "outputs": [],
      "source": [
        "#drop the id from the trainig data\n",
        "data.drop(['id'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ-alz05lOQC"
      },
      "outputs": [],
      "source": [
        "#drop the id from the test data\n",
        "test.drop(['id'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "HCscTIKPhhWk",
        "outputId": "ee479c56-51cc-492a-a68e-0c54b233fee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  label\n",
              "0      A group of friends began to volunteer at a hom...      0\n",
              "1      British Prime Minister @Theresa_May on Nerve A...      0\n",
              "2      In 1961, Goodyear released a kit that allows P...      0\n",
              "3      Happy Birthday, Bob Barker! The Price Is Right...      0\n",
              "4      Obama to Nation: 聙\"Innocent Cops and Unarmed Y...      0\n",
              "...                                                  ...    ...\n",
              "59995  Finish Sniper Simo H盲yh盲 during the invasion o...      0\n",
              "59996  Nigerian Prince Scam took $110K from Kansas ma...      1\n",
              "59997  Is It Safe To Smoke Marijuana During Pregnancy...      0\n",
              "59998  Julius Caesar upon realizing that everyone in ...      0\n",
              "59999  Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...      1\n",
              "\n",
              "[60000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5297af9c-298d-40de-a962-bf1339b29f70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A group of friends began to volunteer at a hom...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows P...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5297af9c-298d-40de-a962-bf1339b29f70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5297af9c-298d-40de-a962-bf1339b29f70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5297af9c-298d-40de-a962-bf1339b29f70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "X7gkZTJEhhY8",
        "outputId": "6d3a9c97-aa3d-4b66-d53c-03eb45eb77f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text\n",
              "0                                             stargazer \n",
              "1                                                   yeah\n",
              "2      PD: Phoenix car thief gets instructions from Y...\n",
              "3      As Trump Accuses Iran, He Has One Problem: His...\n",
              "4                           \"Believers\" - Hezbollah 2011\n",
              "...                                                  ...\n",
              "59146                  Bicycle taxi drivers of New Delhi\n",
              "59147  Trump blows up GOP's formula for winning House...\n",
              "59148  Napoleon returns from his exile on the island ...\n",
              "59149   Deep down he always wanted to be a ballet dancer\n",
              "59150  Toddler miraculously survives 6-story fall lan...\n",
              "\n",
              "[59151 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f53e5eb6-cf4d-4c03-9014-1414679a347d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PD: Phoenix car thief gets instructions from Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>Trump blows up GOP's formula for winning House...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>Napoleon returns from his exile on the island ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>Toddler miraculously survives 6-story fall lan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f53e5eb6-cf4d-4c03-9014-1414679a347d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f53e5eb6-cf4d-4c03-9014-1414679a347d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f53e5eb6-cf4d-4c03-9014-1414679a347d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co7F2Md1iakE"
      },
      "source": [
        "##**pre-preocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpCYAyOXjEjc"
      },
      "source": [
        "####**text processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlkiP3ZhIX9"
      },
      "source": [
        "----\n",
        "\n",
        "**We tried different techniques to clean the data**:\n",
        "- I am using feature selection ***Bag of words***\n",
        "- Removing the leter s at the end of every verb to get back to the infentive (not always right)\n",
        "\n",
        "- Keep only ASCII + European Chars and whitespace, no digits.\n",
        "- remove any html tags.\n",
        "- remove single letter chars\n",
        "- convert the upper case to lower case\n",
        "\n",
        "----\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXQFHIw0hhbV",
        "outputId": "89b2654b-77fc-4132-ea0d-c67d12e4d92f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#nltk is the res[posable for importting the nlp functions and library\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "#text processing \n",
        "\n",
        "def clean_text(text):\n",
        "   \n",
        "    #convert all whitespaces (tabs etc.) to single wspace and remove the s from the verb \n",
        "    RE_WSPACE = re.compile(r\"http\\s+\", re.IGNORECASE)\n",
        "\n",
        "    #remove any html tags (< /br> often found)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "\n",
        "    #Keep only ASCII + European Chars and whitespace, no digits\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-zA-z ]\", re.IGNORECASE)\n",
        "\n",
        "    #remove single letter chars\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zA-z]\\b\", re.IGNORECASE)\n",
        "    \n",
        "\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    # we tokenize the data (split the data into words/toknizer)\n",
        "    word_tokens = word_tokenize(text)\n",
        "\n",
        "    # keep the lower case as it is \n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    # # convert the upper case to lower case\n",
        "    # words_filtered = [stemmer.stem(word) for word in words_tokens_lower if word not in stop_words]\n",
        "    # # \n",
        "    text_clean = \" \".join(words_tokens_lower)\n",
        "\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1cPFRBNFbpG"
      },
      "outputs": [],
      "source": [
        "# data['text_clean']=data['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F87-aJ7xHm2g"
      },
      "outputs": [],
      "source": [
        "# test['text_clean']=test['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRoDGfkYhhdj"
      },
      "outputs": [],
      "source": [
        "#delete the words that it's lenght is less than zero in the training data\n",
        "# Clean Comments\n",
        "data[\"text_clean\"] = data.loc[data[\"text\"].str.len() > 0, \"text\"]\n",
        "\n",
        "data[\"text_clean\"] = data[\"text\"].map(\n",
        "    lambda x: clean_text(x) if isinstance(x, str) else x\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5igzKClIwq7k"
      },
      "outputs": [],
      "source": [
        "#delete the words that it's lenght is less than zero in the test data\n",
        "# Clean Comments\n",
        "test[\"text_clean\"] = test.loc[test[\"text\"].str.len() > 0, \"text\"]\n",
        "test[\"text_clean\"] = test[\"text\"].map(\n",
        "    lambda x: clean_text(x) if isinstance(x, str) else x\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "j14ax8UdkoNH",
        "outputId": "0cf26939-30d4-4028-c9eb-1e162d40f4df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label  \\\n",
              "0  A group of friends began to volunteer at a hom...      0   \n",
              "1  British Prime Minister @Theresa_May on Nerve A...      0   \n",
              "2  In 1961, Goodyear released a kit that allows P...      0   \n",
              "\n",
              "                                          text_clean  \n",
              "0  group of friends began to volunteer at homeles...  \n",
              "1  british prime minister theresa_may on nerve at...  \n",
              "2  in goodyear released kit that allows ps to be ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42d48308-6e14-4df5-b0a8-2f2e95b2642a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A group of friends began to volunteer at a hom...</td>\n",
              "      <td>0</td>\n",
              "      <td>group of friends began to volunteer at homeles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve A...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minister theresa_may on nerve at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows P...</td>\n",
              "      <td>0</td>\n",
              "      <td>in goodyear released kit that allows ps to be ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42d48308-6e14-4df5-b0a8-2f2e95b2642a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42d48308-6e14-4df5-b0a8-2f2e95b2642a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42d48308-6e14-4df5-b0a8-2f2e95b2642a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VeiyJS2iirEC",
        "outputId": "62f59ed5-de56-46ee-fd55-be94c8a6b856"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  \\\n",
              "0                                             stargazer    \n",
              "1                                                   yeah   \n",
              "2      PD: Phoenix car thief gets instructions from Y...   \n",
              "3      As Trump Accuses Iran, He Has One Problem: His...   \n",
              "4                           \"Believers\" - Hezbollah 2011   \n",
              "...                                                  ...   \n",
              "59146                  Bicycle taxi drivers of New Delhi   \n",
              "59147  Trump blows up GOP's formula for winning House...   \n",
              "59148  Napoleon returns from his exile on the island ...   \n",
              "59149   Deep down he always wanted to be a ballet dancer   \n",
              "59150  Toddler miraculously survives 6-story fall lan...   \n",
              "\n",
              "                                              text_clean  \n",
              "0                                              stargazer  \n",
              "1                                                   yeah  \n",
              "2      pd phoenix car thief gets instructions from yo...  \n",
              "3      as trump accuses iran he has one problem his o...  \n",
              "4                                    believers hezbollah  \n",
              "...                                                  ...  \n",
              "59146                  bicycle taxi drivers of new delhi  \n",
              "59147  trump blows up gop formula for winning house r...  \n",
              "59148  napoleon returns from his exile on the island ...  \n",
              "59149     deep down he always wanted to be ballet dancer  \n",
              "59150  toddler miraculously survives story fall landi...  \n",
              "\n",
              "[59151 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdcb69a6-d01e-4c50-8d13-e934cff8dbf3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stargazer</td>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yeah</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PD: Phoenix car thief gets instructions from Y...</td>\n",
              "      <td>pd phoenix car thief gets instructions from yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His...</td>\n",
              "      <td>as trump accuses iran he has one problem his o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "      <td>believers hezbollah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "      <td>bicycle taxi drivers of new delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>Trump blows up GOP's formula for winning House...</td>\n",
              "      <td>trump blows up gop formula for winning house r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>Napoleon returns from his exile on the island ...</td>\n",
              "      <td>napoleon returns from his exile on the island ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "      <td>deep down he always wanted to be ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>Toddler miraculously survives 6-story fall lan...</td>\n",
              "      <td>toddler miraculously survives story fall landi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdcb69a6-d01e-4c50-8d13-e934cff8dbf3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdcb69a6-d01e-4c50-8d13-e934cff8dbf3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdcb69a6-d01e-4c50-8d13-e934cff8dbf3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cI9gpUytkoP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01581974-6e86-4661-9535-cd73b392f23b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "to       30592\n",
              "of       29236\n",
              "in       23623\n",
              "and      19815\n",
              "for      12358\n",
              "it       11395\n",
              "on       11267\n",
              "this     10359\n",
              "is       10039\n",
              "with      8518\n",
              "from      7510\n",
              "my        7309\n",
              "that      7058\n",
              "you       6544\n",
              "his       6413\n",
              "at        6363\n",
              "by        5467\n",
              "was       5462\n",
              "he        5248\n",
              "after     5142\n",
              "an        4557\n",
              "has       4212\n",
              "as        4190\n",
              "they      3959\n",
              "are       3796\n",
              "be        3484\n",
              "out       3415\n",
              "have      3413\n",
              "[         3262\n",
              "]         3241\n",
              "one       3165\n",
              "her       3127\n",
              "new       3010\n",
              "but       2974\n",
              "who       2913\n",
              "like      2912\n",
              "up        2856\n",
              "their     2852\n",
              "not       2787\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from bokeh.models import NumeralTickFormatter\n",
        "# Word Frequency of most common words\n",
        "word_freq = pd.Series(\" \".join(data[\"text_clean\"]).split()).value_counts()\n",
        "word_freq[1:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGC699nExeIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74edf79e-dfc2-4fc3-9df3-8d0f42532307"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "of          9283\n",
              "in          8732\n",
              "to          8658\n",
              "this        7973\n",
              "on          4718\n",
              "my          4676\n",
              "and         4412\n",
              "psbattle    4396\n",
              "for         4037\n",
              "is          3585\n",
              "it          3423\n",
              "with        3076\n",
              "at          2727\n",
              "you         2627\n",
              "from        2605\n",
              "that        2078\n",
              "his         1910\n",
              "like        1781\n",
              "by          1547\n",
              "was         1527\n",
              "has         1515\n",
              "man         1485\n",
              "an          1480\n",
              "after       1418\n",
              "he          1398\n",
              "out         1233\n",
              "me          1230\n",
              "new         1200\n",
              "one         1164\n",
              "[           1114\n",
              "up          1111\n",
              "not         1108\n",
              "dog         1102\n",
              "looks       1101\n",
              "]           1086\n",
              "as          1086\n",
              "found       1079\n",
              "are         1075\n",
              "be          1064\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Word Frequency of most common words (test)\n",
        "word_freq_test = pd.Series(\" \".join(test[\"text_clean\"]).split()).value_counts()\n",
        "word_freq_test[1:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3ox0GW9koSL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "20991666-fbe0-4e3a-f627-10f6a0ce0090"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          index  freq\n",
              "0  renegotiated     1\n",
              "1         veafo     1\n",
              "2          aecf     1\n",
              "3         scute     1\n",
              "4         gular     1\n",
              "5         febba     1\n",
              "6         ctrap     1\n",
              "7         aurka     1\n",
              "8         marut     1\n",
              "9         wahre     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c97498ba-9dd3-4228-b70b-b873cfd367c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>renegotiated</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>veafo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aecf</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>scute</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gular</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>febba</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ctrap</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>aurka</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>marut</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>wahre</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c97498ba-9dd3-4228-b70b-b873cfd367c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c97498ba-9dd3-4228-b70b-b873cfd367c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c97498ba-9dd3-4228-b70b-b873cfd367c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# list most uncommon words\n",
        "word_freq[-10:].reset_index(name=\"freq\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pY0mtxOSwTg"
      },
      "source": [
        "####Delet outliars from the label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsB5V7JQtQM9"
      },
      "source": [
        "After i res the label data i realized that i got three label and there is a huge difference between the classes so the the third class is "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBPFf0eCkoUy",
        "outputId": "d756df31-3e75-456c-cc26-41995e77cf1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.536200\n",
              "1    0.459933\n",
              "2    0.003867\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Distribution of ratings\n",
        "data[\"label\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iH_yrWhkoZz"
      },
      "outputs": [],
      "source": [
        "#grtting the label that less than 2\n",
        "data = data[data['label'] != 2 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLU0S7n8kocr",
        "outputId": "3d4b74df-158f-463d-b3dd-9073b01ab5af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.538281\n",
              "1    0.461719\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Distribution of ratings\n",
        "data[\"label\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8og_rXjPnMYf"
      },
      "source": [
        "#### splitting trainig data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgl9IrDHhUV5"
      },
      "outputs": [],
      "source": [
        "#splitting the data to feature and label\n",
        "X=data[\"text_clean\"]\n",
        "y=data[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJdeDt_a7Z3h",
        "outputId": "74c4debf-0300-4001-b438-5c6dee42137b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifiers to test: ['LogisticRegression', 'LinearSVC', 'RandomForestClassifier', 'XGBClassifier', 'MLPClassifier']\n"
          ]
        }
      ],
      "source": [
        "# models to test\n",
        "classifiers = [\n",
        "    LogisticRegression(solver=\"sag\", random_state=1),\n",
        "    LinearSVC(random_state=1),\n",
        "    RandomForestClassifier(random_state=1),\n",
        "    XGBClassifier(random_state=1),\n",
        "    MLPClassifier(\n",
        "        random_state=1,\n",
        "        solver=\"adam\",\n",
        "        hidden_layer_sizes=(12, 12, 12),\n",
        "        activation=\"relu\",\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=1,\n",
        "    ),\n",
        "]\n",
        "# get names of the objects in list (too lazy for c&p...)\n",
        "names = [re.match(r\"[^\\(]+\", name.__str__())[0] for name in classifiers]\n",
        "print(f\"Classifiers to test: {names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**Trial_1**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uELGYcKvcKyN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QivPvBsUUSFe"
      },
      "source": [
        "---\n",
        "###**Logistic Regression**\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYIH4UZYEoVL"
      },
      "source": [
        "**In this trail im using** : \n",
        "- **Classifier** : Logistic Regression \n",
        "- **Hyperparameter tuning**:  GridSearch with Validation set \n",
        "- **analysier**: word  \n",
        "\n",
        "----\n",
        "Logistic regression is not a classifier. It is a probability/risk estimator, it allows for and expects \"close calls\". It will lead to optimum decision making because it does not try to trick the predictive signal into incorporating a utility function that is implicit whenever you classify observations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        " ---\n",
        "**My thoughts**\n",
        "\n",
        "- since LR not in the top of the classifiers used in the text classification i think the model will give not too high roc_auc score\n",
        "\n",
        "----\n",
        "---"
      ],
      "metadata": {
        "id": "hRIYzlcsTt0x"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2LjTtC1GrO1"
      },
      "source": [
        "---- \n",
        "- **Here we have the pipeline it has the Vectorizer and the Classifier, and we using the Logistic Regression**.\n",
        "\n",
        "- **After that we fit the data using the Pipline**.\n",
        "\n",
        "- **We are using the validation set to get the number of cv** \n",
        "\n",
        "----\n",
        "**the experimental protocol used is 'Hold out method'**\n",
        "\n",
        "The following is the process of using the hold-out method for model evaluation:\n",
        "\n",
        "- Split the dataset into two parts (preferably based on 70-30% split; However, the percentage split will vary)\n",
        "\n",
        "- Train the model on the training dataset; While training the model, some fixed set of hyper parameters is selected.\n",
        "\n",
        "- Test or evaluate the model on the held-out test dataset\n",
        "Train the final model on the entire dataset to get a model which can generalize better on the unseen or future dataset. \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-nU7UEKBWEM",
        "outputId": "9dcb74ef-20ab-429c-80c6-5f68fd008f75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(norm='l2')), ('my_classifier', LogisticRegression())])\n",
        "pipe.fit(X, y)\n",
        "\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "X_train2, X_val, y_train2, y_val = train_test_split(\n",
        "    X, y, train_size = 0.8, stratify = y, random_state = 2022)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train2.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBcvtWOSIfZL"
      },
      "source": [
        "**Hyperparameters used in Grid search** :\n",
        "\n",
        "---\n",
        "- **penalty** : the regulrization to control overfitting \n",
        "\n",
        "- **C** : is inverse of regularization, the larger the C, the smaller is regularization, means that your algo is more prone to overfit the data\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages.\n",
        "\n",
        "-----\n",
        "**Hyperparameters used in TfidfVectorizer** :\n",
        "\n",
        "----\n",
        "\n",
        "- **ngram_range**: The lower and upper boundary of the range of n-values for different n-grams to be extracted.and we gave it the range of (1,2),(1,3) i was trying different compination to see the best works for it and (1,2) was the best fit for it.\n",
        "\n",
        "- **max_df** : When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold. i put two values to see the best fit and 0.3 was the best fit.\n",
        "\n",
        "- **min_df**: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.i gave it three values and i kept changing them but this results was the best.\n",
        "\n",
        "- **analyzer**: Whether the feature should be made of word or character n-grams. here we triad the word n gran analyzer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKEAE4c9Wfn4",
        "outputId": "706efa0d-46da-4e77-ac0e-a9ad8586e886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
            "0.8870358286194489 {'my_classifier__C': 0.6, 'my_classifier__penalty': 'l2', 'my_classifier__solver': 'newton-cg', 'tfidf__analyzer': 'word', 'tfidf__max_df': 0.3, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 30, 5),\n",
        "    \"tfidf__analyzer\": [\"word\"],\n",
        "\n",
        "    \"my_classifier__penalty\" : ['l2'],  \n",
        "    'my_classifier__C' : [0.6], # 1.5 the best score for me \n",
        "    'my_classifier__solver': ['newton-cg']       \n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_clf = GridSearchCV(pipe, params, n_jobs=2,cv=pds,verbose=1, scoring=\"roc_auc\")\n",
        "\n",
        "#fit the data using the best hyperparameters\n",
        "pipe_clf.fit(X, y)\n",
        "print(pipe_clf.best_score_,pipe_clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "----\n",
        "\n",
        "- After performaing the model and compare with kagel scores i realized that the model perform very good.it gave me an accuracy = 0.887.\n",
        "but when i uploaded in kagel it gave me 0.862 which is pretty good comparig to the other models.\n",
        "\n",
        "- **\"my thoughts\"** \n",
        "\n",
        " - i thought the model will give me a lower accuracy, according to the classifiers that works well with  text classification LR wasn't one of them.but from what we see the Logistc regrssion with the value of the previous hyperparameter works well together.\n",
        "\n",
        "---\n",
        "----"
      ],
      "metadata": {
        "id": "CsFHLuWzPZip"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WWbe0K9fVki"
      },
      "outputs": [],
      "source": [
        "#predect the the testing data\n",
        "y_test_pred_ = pipe_clf.predict_proba(test[\"text_clean\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYPyOGkxkTH7"
      },
      "outputs": [],
      "source": [
        "#Write the output in a file \n",
        "write_ = pd.DataFrame({'id': id_test,'label': y_test_pred_[:,1]})\n",
        "write_.to_csv('/content/drive/MyDrive/DM_assignment_3/assignment2_Rand.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "##**Trial_2**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "TIwI0DZacbWR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kz9LZPdEP3D"
      },
      "source": [
        "---\n",
        "###**Logistic Regression**\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pRDuTYgIOHS"
      },
      "source": [
        "**In this trail im using** : \n",
        "- **Classifier**: Logistic Regression \n",
        "- **Hyperparameter tuning**: GridSearch with Validation set \n",
        "- **analysier**: char  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        " ---\n",
        "**My thoughts**\n",
        "\n",
        "- After the first trial i got the realize that the Logistic regresiion clasiifier is performing well with this model so im going to try it again with different paramters like the hyperparameter tuning and the analysis, i think the model is going to give a lesser accuracy than the previous one but not so much and that's because of the analysier. \n",
        "\n",
        "----\n",
        "---"
      ],
      "metadata": {
        "id": "ICXUKJXiUT95"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dOPZy7rbCi2"
      },
      "source": [
        "**Hyperparameters used in Grid search** :\n",
        "\n",
        "---\n",
        "- **penalty** : the regulrization to control overfitting \n",
        "\n",
        "- **C** : is inverse of regularization, the larger the C, the smaller is regularization, means that your algo is more prone to overfit the data\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages.\n",
        "\n",
        "-----\n",
        "**Hyperparameters used in TfidfVectorizer** :\n",
        "\n",
        "----\n",
        "\n",
        "- **ngram_range**: The lower and upper boundary of the range of n-values for different n-grams to be extracted.in this trial i tried to change the range to different thong that was the best for this trial and we gave it the range of (1,2) was the best fit for it.\n",
        "\n",
        "- **max_df** : When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold.i put two values to see the best fit and 0.3 was the best fit.\n",
        "\n",
        "- **min_df**: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.i gave it three values and i kept changing them but this results was the best.\n",
        "\n",
        "- **analyzer**: Whether the feature should be made of word or character n-grams.here we triad the character n gran analyzer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaPQryecER_C",
        "outputId": "f6d9c27c-9121-4b4d-e82e-c847f9475203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8506765566377816 {'my_classifier__C': 0.7, 'my_classifier__penalty': 'l2', 'my_classifier__solver': 'newton-cg', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.3, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 3)}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 30, 5),\n",
        "    \"tfidf__analyzer\": [\"char\"],\n",
        "\n",
        "    \"my_classifier__penalty\" : ['l2'],  \n",
        "    'my_classifier__C' : [0.6,0.7],  \n",
        "    'my_classifier__solver': ['newton-cg']       \n",
        "}\n",
        "\n",
        "pipe_clf = GridSearchCV(pipe, params, n_jobs=2,cv=pds,verbose=1, scoring=\"roc_auc\")\n",
        "\n",
        "#fit the data with the hyperparameter tuning\n",
        "pipe_clf.fit(X, y)\n",
        "print(pipe_clf.best_score_,pipe_clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "----\n",
        "\n",
        "- After performaing the model and compare with kagel scores i realized that the model perform not too good.it gave me an accuracy = 0.850.\n",
        "but when i uploaded in kagel it gave me 0.70 which is it's too bad.\n",
        "\n",
        "- **\"my thoughts\"** \n",
        "\n",
        " - i expected the model to give a lower accuracy because of the analyzer.\n",
        "\n",
        "---\n",
        "----"
      ],
      "metadata": {
        "id": "AAsF99qeTLii"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LYagDWrESCB"
      },
      "outputs": [],
      "source": [
        "#predect the the testing data\n",
        "y_test_pred_ = pipe_clf.predict_proba(test[\"text_clean\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmGAZnH4ESFA"
      },
      "outputs": [],
      "source": [
        "#Write the output in a file\n",
        "write_ = pd.DataFrame({'id': id_test,'label': y_test_pred_[:,1]})\n",
        "write_.to_csv('/content/drive/MyDrive/DM_assignment_3/assignment2_LR_char.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        " \n",
        "##**Trial_3**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "viThvKPRcjQy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIA0EDyv66Fu"
      },
      "source": [
        "----\n",
        "###**XGBClassifier**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZz3-G4FMpLz"
      },
      "source": [
        "**In this trail im using** : \n",
        "- **Classifier**: XGBClassifier \n",
        "- **Hyperparameter tunin**g:  GridSearch with Validation set \n",
        "- **analysier**: word \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "---\n",
        "**My thoughts**\n",
        "\n",
        " It can help you to predict any kind of data if you have already predicted data before. You can classify any kind of data. It can be used for text classification too.. it's my first encoter to use this classifier in text classificatoion so i think from what i red that it will give a good accuracy .\n",
        "___\n",
        "---"
      ],
      "metadata": {
        "id": "ZqE2YNOJUsTB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JDME1w0fPh1"
      },
      "source": [
        "----\n",
        "- **Here we have the pipeline it has the Vectorizer and the Classifier i am using the XGBclassifier**.\n",
        "- **After that we fit the data using the Pipline**.\n",
        "\n",
        "- **We are using the validation set to get the nuber of cv** \n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDOt-m-GRZ3E"
      },
      "outputs": [],
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(norm='l2')), ('my_classifier', XGBClassifier())])\n",
        "pipe.fit(X, y)\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "X_train2, X_val, y_train2, y_val = train_test_split(\n",
        "    X, y, train_size = 0.8, stratify = y, random_state = 2022)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train2.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9gygEduW2Nt"
      },
      "source": [
        "--- \n",
        "\n",
        "**Hyperparameters used in Grid search** :\n",
        "\n",
        "---\n",
        "- **max_depth** : Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.i tried different values and i got to conclusion that thae calues im using (7) is the best value of all the values i used. \n",
        "\n",
        "- **gamma**: Minimum loss reduction required to make a further partition on a leaf node of the tree.the value i used was the best of all the valus i used before[0.5 ,1, 1.5]\n",
        "\n",
        "- **n_estimators** : A object of that type is instantiated for each grid point. This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages.\n",
        "\n",
        "-----\n",
        "**Hyperparameters used in TfidfVectorizer** :\n",
        "\n",
        "----\n",
        "\n",
        "- **ngram_range**: The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
        "\n",
        "- **max_df** : When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
        "\n",
        "- **min_df**: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
        "\n",
        "- **analyzer**: Whether the feature should be made of word or character n-grams\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekRB0dfE666_",
        "outputId": "7f04759a-c9db-4861-d2b6-306e5324af15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 60 candidates, totalling 60 fits\n",
            "0.8612442740364465 {'my_classifier__gamma': 1, 'my_classifier__learning_rate': 0.1, 'my_classifier__max_depth': 7, 'my_classifier__n_estimators': 300, 'tfidf__analyzer': 'word', 'tfidf__max_df': 0.3, 'tfidf__min_df': 15, 'tfidf__ngram_range': (1, 3)}\n"
          ]
        }
      ],
      "source": [
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 30, 5),\n",
        "     \"tfidf__analyzer\": [\"word\"],\n",
        "\n",
        "    \"my_classifier__max_depth\" : [6,7],\n",
        "    'my_classifier__gamma' :[1],\n",
        "    'my_classifier__learning_rate' :[0.05,0.01,0.1],\n",
        "    'my_classifier__n_estimators':  [300]      \n",
        "}\n",
        "\n",
        "pipe_clf = GridSearchCV(pipe, params, n_jobs=2,cv=pds,verbose=1, scoring=\"roc_auc\")\n",
        "\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print(pipe_clf.best_score_,pipe_clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "----\n",
        "- After performaing the model and compare with kagel scores i realized that the model perform not not too good.it gave me an accuracy = 0.861.\n",
        "but when i uploaded in kagel it gave me 0.83 which is it's too bad.\n",
        "\n",
        "- **\"my thoughts\"** \n",
        "\n",
        " - Well the model give not too bad accuracy comparing the other classifier.. i think the compination of hyperparameter didn't work well as expected. at the next trial im going to use the same classifier but with different hyperparamter. . \n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "mTXsQ5duVIfa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bCQ_nAn66_2"
      },
      "outputs": [],
      "source": [
        "#predect the the testing data\n",
        "y_test_pred_2 = pipe_clf.predict_proba(test[\"text_clean\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWPAvJeJ9Ipv"
      },
      "outputs": [],
      "source": [
        "#Write the output in a file\n",
        "write_ = pd.DataFrame({'id': id_test,'label': y_test_pred_2[:,1]})\n",
        "write_.to_csv('/content/drive/MyDrive/DM_assignment_3/assignment2_xgbost.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qghBT_r4Rfhz"
      },
      "source": [
        "---\n",
        "##**Trial_4**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqBYnu9gRf0r"
      },
      "source": [
        "----\n",
        "###**XGBClassifier**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQTTGNc4SYJU"
      },
      "source": [
        "**In this trail im using** : \n",
        "- Classifier: XGBClassifier \n",
        "- Hyperparameter tuning:  RandomizedSearchCV with Validation set \n",
        "- analysier: char  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5shEcnWOdcPV"
      },
      "source": [
        "--- \n",
        "\n",
        "**Hyperparameters used in Randomsearch** :\n",
        "\n",
        "---\n",
        "- **max_depth** : Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
        "\n",
        "- **gamma**: Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
        "\n",
        "- **n_estimators** : A object of that type is instantiated for each grid point. This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages.\n",
        "\n",
        "-----\n",
        "**Hyperparameters used in TfidfVectorizer** :\n",
        "\n",
        "----\n",
        "\n",
        "- **ngram_range**: The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
        "\n",
        "- **max_df** : When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
        "\n",
        "- **min_df**: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
        "\n",
        "- **analyzer**: Whether the feature should be made of word or character n-grams\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjpq5kDERgsc",
        "outputId": "11d82737-10cd-4e78-f6d2-b403b63c492a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
            "0.8513027609784268 {'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 10, 'tfidf__max_df': 0.3, 'tfidf__analyzer': 'char', 'my_classifier__n_estimators': 400, 'my_classifier__max_depth': 6, 'my_classifier__learning_rate': 0.05, 'my_classifier__gamma': 1}\n"
          ]
        }
      ],
      "source": [
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 30, 5),\n",
        "     \"tfidf__analyzer\": [\"char\"],\n",
        "\n",
        "    \"my_classifier__max_depth\" : [6,5],\n",
        "    'my_classifier__gamma' :[0.5, 1, 1.5],\n",
        "    'my_classifier__learning_rate' :[0.05,0.001,],\n",
        "    'my_classifier__n_estimators':  [400]      \n",
        "}\n",
        "\n",
        "pipe_clf = RandomizedSearchCV(pipe, params, n_jobs=2,cv=pds,verbose=1, scoring=\"roc_auc\")\n",
        "\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print(pipe_clf.best_score_,pipe_clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "----\n",
        "\n",
        "- After performaing the model and compare with kagel scores i realized that the model perform not not too good.it gave me an accuracy = 0.85.\n",
        "but when i uploaded in kagel it gave me 0.72 which is it's too bad.\n",
        "\n",
        "- **\"my thoughts\"** \n",
        "\n",
        " - As expected the model gives a lower accuracy because of the analyzer nt to bad it's a bit close to when the analyzer was word. \n",
        "\n",
        "---\n",
        "----"
      ],
      "metadata": {
        "id": "_WFli1FrVxyq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kf-eEVLRg26"
      },
      "outputs": [],
      "source": [
        "#predect the the testing data\n",
        "y_test_pred_2 = pipe_clf.predict_proba(test[\"text_clean\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj3Ld1BGRg-K"
      },
      "outputs": [],
      "source": [
        "#Write the output in a file\n",
        "write_ = pd.DataFrame({'id': id_test,'label': y_test_pred_2[:,1]})\n",
        "write_.to_csv('/content/drive/MyDrive/DM_assignment_3/assignment2_xgbost_RS.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**Trial_5**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "tcqKA3ABcsFK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL39KcZmP_8v"
      },
      "source": [
        "----\n",
        "####**Random forest**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JGF88lAUs8M"
      },
      "source": [
        "**In this trail im using** : \n",
        "- **Classifier**: RamdomForest \n",
        "- **Hyperparameter tuning**:  GridSearchCV with Validation set \n",
        "- **analysier**: word\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "**My thoughts**\n",
        "\n",
        "- it is recommended to test several models regardless of their theoretical performance, because their accuracy is dependent of the training dataset. i don't know how it woll go with this but let's find out.    \n",
        "\n",
        " -----\n",
        " ----"
      ],
      "metadata": {
        "id": "PVsqCJ2sYzAS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG1sWLW2fJBd"
      },
      "source": [
        "----\n",
        "- **Here we have the pipeline it has the Vectorizer and the Classifier i am using the RandomForest**.\n",
        "- **After that we fit the data using the Pipline**.\n",
        "\n",
        "- **We are using the validation set to get the nuber of cv** \n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy_1uURTT2Ws"
      },
      "outputs": [],
      "source": [
        "# feature creation THE PIPLINE\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(norm='l2')), ('my_classifier', RandomForestClassifier())])\n",
        "pipe.fit(X, y)\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "X_train2, X_val, y_train2, y_val = train_test_split(\n",
        "    X, y, train_size = 0.8, stratify = y, random_state = 2022)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train2.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_W0vMaKeF18"
      },
      "source": [
        "--- \n",
        "\n",
        "**Hyperparameters used in Grid search** :\n",
        "\n",
        "---\n",
        "- **max_depth** : Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
        "\n",
        "- **min_samples_leaf**: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression\n",
        "\n",
        "- **min_samples_split**: The minimum number of samples required to split an internal node\n",
        "\n",
        "- **n_estimators** : A object of that type is instantiated for each grid point. This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages.\n",
        "\n",
        "-----\n",
        "**Hyperparameters used in TfidfVectorizer** :\n",
        "\n",
        "----\n",
        "\n",
        "- **ngram_range**: The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
        "\n",
        "- **max_df** : When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
        "\n",
        "- **min_df**: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
        "\n",
        "- **analyzer**: Whether the feature should be made of word or character n-grams\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWymsTDeQD36",
        "outputId": "0718b099-1640-42b2-fd49-707fd6dd5574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 40 candidates, totalling 40 fits\n",
            "0.847952013761037 {'my_classifier__max_depth': 60, 'my_classifier__min_samples_leaf': 4, 'my_classifier__min_samples_split': 5, 'my_classifier__n_estimators': 200, 'tfidf__analyzer': 'word', 'tfidf__max_df': 0.3, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 30, 5),\n",
        "    \"tfidf__analyzer\": [\"word\"],\n",
        "\n",
        "    'my_classifier__max_depth': [50, 60],\n",
        "    'my_classifier__min_samples_leaf': [4],\n",
        "    'my_classifier__min_samples_split': [5, 10],\n",
        "    'my_classifier__n_estimators': [200]      \n",
        "}\n",
        "\n",
        "pipe_clf = GridSearchCV(pipe, params, n_jobs=2,cv=pds,verbose=1, scoring=\"roc_auc\")\n",
        "\n",
        "# fithe the data using the hyperparameter tuning \n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print(pipe_clf.best_score_,pipe_clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "----\n",
        "\n",
        "- After performing we realize that the model perform not too bad comparing to other models.we after triaing diferent compination that was the best that get me this accuracy maybe trying different comoination will make difference in next trial. \n",
        "\n",
        "---\n",
        "----"
      ],
      "metadata": {
        "id": "GRQYeSj_ajJU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHIL059NQFN3"
      },
      "outputs": [],
      "source": [
        "#predect the the test file\n",
        "y_test_pred_3 = pipe_clf.predict_proba(test[\"text_clean\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRjGAJeDQFQt"
      },
      "outputs": [],
      "source": [
        "#Write the the predected value into file\n",
        "write_ = pd.DataFrame({'id': id_test,'label': y_test_pred_3[:,1]})\n",
        "write_.to_csv('/content/drive/MyDrive/DM_assignment_3/assignment2__RF_GS.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**Trial_6**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "TYL0_WgUdj2C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH-AvBXFUixM"
      },
      "source": [
        "----\n",
        "###**Random forest**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooknifrXUogG"
      },
      "source": [
        "**In this trail im using** : \n",
        "- **Classifier**: RandomForst \n",
        "- **Hyperparameter tuning**:  RandomizedSearchCV with Validation set \n",
        "- **analysier**: char  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDbrQcMUz3Nt"
      },
      "source": [
        "--- \n",
        "\n",
        "**Hyperparameters used in Grid search** :\n",
        "\n",
        "---\n",
        "- **max_depth** : Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
        "\n",
        "- **min_samples_leaf**: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression\n",
        "\n",
        "- **min_samples_split**: The minimum number of samples required to split an internal node\n",
        "\n",
        "- **n_estimators** : A object of that type is instantiated for each grid point. This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages.\n",
        "\n",
        "-----\n",
        "**Hyperparameters used in TfidfVectorizer** :\n",
        "\n",
        "----\n",
        "\n",
        "- **ngram_range**: The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
        "\n",
        "- **max_df** : When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
        "\n",
        "- **min_df**: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
        "\n",
        "- **analyzer**: Whether the feature should be made of word or character n-grams\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGFb0WTeT6Mq",
        "outputId": "5577a7ca-2d1e-4ce2-a33c-5752386bfe6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8377471172905129 {'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 20, 'tfidf__max_df': 0.3, 'tfidf__analyzer': 'char', 'my_classifier__n_estimators': 800, 'my_classifier__min_samples_split': 10, 'my_classifier__min_samples_leaf': 1, 'my_classifier__max_depth': 60}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 30, 5),\n",
        "    \"tfidf__analyzer\": [\"char\"],\n",
        "\n",
        "    'my_classifier__max_depth': [30, 50, 60],\n",
        "    'my_classifier__min_samples_leaf': [1, 2, 4],\n",
        "    'my_classifier__min_samples_split': [5, 10],\n",
        "    'my_classifier__n_estimators': [800]      \n",
        "}\n",
        "\n",
        "pipe_clf = RandomizedSearchCV(pipe, params, n_jobs=2,cv=pds,verbose=1, scoring=\"roc_auc\")\n",
        "#fit the data using the hupyparameter tunning\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print(pipe_clf.best_score_,pipe_clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "----\n",
        "\n",
        "- After performaing the model and compare with kagel scores i realized that the model perform not not too good.i will definatly try differnt compination next time.\n",
        "---\n",
        "----"
      ],
      "metadata": {
        "id": "X0guO5MZaz_b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wGFCnhUHT6Ti"
      },
      "outputs": [],
      "source": [
        "# predect the the test file \n",
        "y_test_pred_3 = pipe_clf.predict_proba(test[\"text_clean\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UZ6OPDOAT6XF"
      },
      "outputs": [],
      "source": [
        "#wRITTING THE OUTPUT in a file\n",
        "write_ = pd.DataFrame({'id': id_test,'label': y_test_pred_3[:,1]})\n",
        "write_.to_csv('/content/drive/MyDrive/DM_assignment_3/assignment2_RF_RS.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**Questions**\n"
      ],
      "metadata": {
        "id": "NSG4diiRYtBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "1-**What is the difference between Character n-gram and Word n-gram**? **Which one tends to suffer more from the OOV issue**?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0hFzhvxJY1i8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word N-grams**\n",
        "-  means a sequence of N words. in NLP n-grams are used for a variety of things. Some examples include auto completion of sentences (such as the one we see in Gmail these days), auto spell check (yes, we can do that as well), and to a certain extent, we can check for grammar in a given sentence. \n",
        "\n",
        "- The alignment systems are traditionally based on word\n",
        "N-grams splitting. The observation of the morphological variety of languages, even inside a single linguistic family, quickly shows\n",
        "that the word granularity is inadequate to provide a widely multilingual system, i.e. a language independent system able to handle\n",
        "flexional languages as well as positional languages. Instead, when starting from a multilingual collection to focus on pairs of texts,\n",
        "we defend that character N-grams alignment is more efficient than word N-grams alignment.\n",
        "\n",
        "\n",
        "**Character N-grams**\n",
        "\n",
        "- Character N-grams (of at least 3 characters) that are common to words meaning “transport” in the same texts sample in French, Spanish and Greek and their respective frequency.The idea of considering character n-grams rather than words has been used for author identification ,language identification, speech analysis, text categorization, numerical classification of multilingual documents and information retrieval. in most of the NLP applications, the number N of characters considered (N-grams) is defined before hand and constant. In general, the character N-grams considered are bigrams or trigrams (4-grams or\n",
        "5-grams in the case of Mcnamee & Mayfield (2004). On the contrary, we consider character N-grams2 of various size:\n",
        "we consider all repeated strings of our corpus (frequency equal or greater than 2). \n",
        "\n",
        " **Word N-grams is the one suggering from out-of-vocabulary (OOV) words**\n",
        " \n"
      ],
      "metadata": {
        "id": "rQCpUQpmY1l7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "2- **What is the difference between stop word removal and stemming? Are these techniques language-dependent**?\n",
        "\n",
        "----\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wOLxal1qY1p7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stop word elimination and stemming are commonly used method in indexing**.\n",
        "\n",
        "**Both stemming and stopword removal are pretty popular preprocessing techniques for text classification**.\n",
        "\n",
        "\n",
        "**Stop words**\n",
        "\n",
        "-  Stop words are high frequency words that have little semantic weight and are thus unlikely to help the retrieval process. Usual practice in IR is to drop them from index.\n",
        "\n",
        "**Stemming** \n",
        " \n",
        " - Stemming conflates morphological variants of words in its root or stem. It\n",
        "frees user from worrying about the truncation and inflection while framing queries and helps in reducing index size. Stemming does help in improving the retrieval performance. Particularly, recall is expected to improve after stemming.\n",
        "-----\n",
        "\n",
        "- **We do not always remove the stop words. The removal of stop words is highly dependent on the task we are performing and the goal we want to achieve**.\n",
        "\n",
        "\n",
        "- **The stemming or lemmatization of words is the most popular language-dependent approach to document retrieval**. **We use the set of stemmers implemented in the Snowball language** \n",
        "\n",
        "- **stop word and stemming is a word deppendant**"
      ],
      "metadata": {
        "id": "5WlnhoSwY1s-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ---\n",
        " **3**-**Is tokenization techniques language dependent? Why**?\n",
        "\n",
        " ----"
      ],
      "metadata": {
        "id": "A7pQ5EHURDBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tokenization is a way of separating a piece of text into smaller units called tokens. \n",
        "\n",
        "- **Yes** tokenization is language dependent.\n",
        "\n",
        "- **As tokens are the building blocks of Natural Language, the most common way of processing the raw text happens at the token level**.**Tokenization is the foremost step while modeling text data. Tokenization is performed on the corpus to obtain tokens**.\n",
        "\n",
        "- in english "
      ],
      "metadata": {
        "id": "nNvF4MN_RDGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "4-**What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them**?\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "UBnnhTj9RDNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TfidfVectorizer and CountVectorizer both are methods for converting text data into vectors as model can process only numerical data.\n",
        "\n",
        "\n",
        "- **CountVectorizer**: Counts the frequency of all words in our corpus, sorts them and grabs the most recurring features (using max_features hyperparameter). But these results are mostly biased and our model might loose out on some of the important less frequent features.\n",
        "\n",
        "\n",
        "- **TFIDFVectorizer**: TFIDF is a statistical measure said to have fixed the issues with CountVectorizer in some way. It consists of 2 parts, TF (Term Frequency) multiplied with IDF (Inverse Document Frequency). The main intuition being some words that appear frequently in 1 document and less frequently in other documents could be considered as providing extra insight for that 1 document and could help our model learn from this additional piece of information. In short, common words are penalized. These are relative frequencies identified as floating point numbers.\n",
        "\n",
        "- **No** it's not feasible to use all of them one time , it cuz it differe from application to another and another.\n",
        "\n",
        "-  an n-gram of size 1 is referred to as a \"unigram\"; size 2 is a \"bigram\"; size 3 is a \"trigram\". When N>3 this is usually referred to as four grams or five grams and so on.\n"
      ],
      "metadata": {
        "id": "iwlFPKKaRDRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refreance\n",
        "\n",
        "- https://towardsdatascience.com/text-pre-processing-stop-words-removal-using-different-libraries-f20bac19929a\n",
        "\n",
        "- https://link.springer.com/content/pdf/10.1007/978-81-8489-203-1_31.pdf\n",
        "\n",
        "- https://irlab.science.uva.nl/wp-content/papercite-data/pdf/kamps-language-dependent-2004.pdf\n",
        "\n",
        "- https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/\n",
        "\n",
        "- https://www.quora.com/How-are-TF-IDF-vectorizers-with-n-gram-features-created"
      ],
      "metadata": {
        "id": "0kBlXYFOILHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Gqu7dUURYu6C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Assignmentt_3.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}